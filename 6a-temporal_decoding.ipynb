{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate statistics (decoding / MVPA) on MEG/EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : Alexandre Gramfort\n",
    "\n",
    "See more info on decoding on this page: https://mne.tools/stable/auto_tutorials/machine-learning/plot_sensors_decoding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add plot inline in the page\n",
    "%matplotlib qt\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the mne package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the log-level to 'WARNING' so the output is less verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the sample dataset. If you don't already have it, it will be downloaded automatically (but be patient approx. 2GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')\n",
    "\n",
    "# Change the following path to where the folder ds000117-practical is on your disk\n",
    "data_path = os.path.expanduser(\"~/work/data/ds000117-practical/\")\n",
    "\n",
    "raw_fname = os.path.join(data_path,\n",
    "    'derivatives/meg_derivatives/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_proc-sss_meg.fif')\n",
    "\n",
    "epochs_fname = raw_fname.replace('_meg.fif', '-epo.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and crop epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EpochsFIF  |   79 events (all good), -0.2 - 0.25 sec, baseline [-0.2, 0], ~38.3 MB, data loaded,\n",
       " 'face/famous/first': 13\n",
       " 'face/famous/immediate': 3\n",
       " 'face/famous/long': 6\n",
       " 'face/unfamiliar/first': 17\n",
       " 'face/unfamiliar/immediate': 4\n",
       " 'face/unfamiliar/long': 6\n",
       " 'scrambled/first': 15\n",
       " 'scrambled/immediate': 9\n",
       " 'scrambled/long': 6>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = mne.read_epochs(epochs_fname)\n",
    "epochs.crop(None, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the ERF and contrast between left and rigth response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_face = epochs['face'].average()\n",
    "evoked_scrambled = epochs['scrambled'].average()\n",
    "evoked_contrast = mne.combine_evoked([evoked_face, evoked_scrambled],\n",
    "                                     [0.5, -0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evoked_face.plot()\n",
    "fig = evoked_scrambled.plot()\n",
    "fig = evoked_contrast.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some topographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = -4, 4\n",
    "fig = evoked_face.plot_topomap(ch_type='eeg', contours=0, vmin=vmin, vmax=vmax)\n",
    "fig = evoked_scrambled.plot_topomap(ch_type='eeg', contours=0, vmin=vmin, vmax=vmax)\n",
    "fig = evoked_contrast.plot_topomap(ch_type='eeg', contours=0, vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's see if we can classify single trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a chance at 50% accuracy equalize epoch count in each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<EpochsFIF  |   60 events (all good), -0.2 - 0.25 sec, baseline [-0.2, 0], ~30.9 MB, data loaded,\n",
       "  'face/famous/first': 7\n",
       "  'face/famous/immediate': 3\n",
       "  'face/famous/long': 4\n",
       "  'face/unfamiliar/first': 10\n",
       "  'face/unfamiliar/immediate': 3\n",
       "  'face/unfamiliar/long': 3\n",
       "  'scrambled/first': 15\n",
       "  'scrambled/immediate': 9\n",
       "  'scrambled/long': 6>,\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 39, 40, 53, 54, 63, 68, 75, 76,\n",
       "        77, 78]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.equalize_event_counts(['face', 'scrambled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EpochsFIF  |   60 events (all good), -0.2 - 0.25 sec, baseline [-0.2, 0], ~30.9 MB, data loaded,\n",
      " 'face/famous/first': 7\n",
      " 'face/famous/immediate': 3\n",
      " 'face/famous/long': 4\n",
      " 'face/unfamiliar/first': 10\n",
      " 'face/unfamiliar/immediate': 3\n",
      " 'face/unfamiliar/long': 3\n",
      " 'scrambled/first': 15\n",
      " 'scrambled/immediate': 9\n",
      " 'scrambled/long': 6>\n"
     ]
    }
   ],
   "source": [
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifier takes as input an `x` and return `y` (0 or 1). Here x will be the data at one time point on all gradiometers (hence the term multivariate). We work with all sensors jointly and try to find a discriminative pattern between 2 conditions to predict the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification we will use the scikit-learn package (http://scikit-learn.org/) and MNE functions \n",
    "\n",
    "`\n",
    "Reference:\n",
    "Scikit-learn: Machine Learning in Python,\n",
    "Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face/famous/first': 5,\n",
       " 'face/famous/immediate': 6,\n",
       " 'face/famous/long': 7,\n",
       " 'face/unfamiliar/first': 13,\n",
       " 'face/unfamiliar/immediate': 14,\n",
       " 'face/unfamiliar/long': 15,\n",
       " 'scrambled/first': 17,\n",
       " 'scrambled/immediate': 18,\n",
       " 'scrambled/long': 19}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# make response vector\n",
    "y = np.zeros(len(epochs.events), dtype=int)\n",
    "y[epochs.events[:, 2] < 17] = 1  # 1 means face\n",
    "\n",
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 204, 136)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = epochs.copy().pick_types(meg='grad').get_data()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 27744)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = X.reshape(60, -1)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94444444 0.97222222 0.77777778 0.94444444 0.80555556]\n",
      "Accuracy = 0.889 (std 0.081)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1e6, solver='liblinear')\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "scores = cross_val_score(logreg, XX, y, cv=cv, scoring='roc_auc')\n",
    "print(scores)\n",
    "print('Accuracy = %0.3f (std %.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        2., 0., 1.]),\n",
       " array([0.77777778, 0.7875    , 0.79722222, 0.80694444, 0.81666667,\n",
       "        0.82638889, 0.83611111, 0.84583333, 0.85555556, 0.86527778,\n",
       "        0.875     , 0.88472222, 0.89444444, 0.90416667, 0.91388889,\n",
       "        0.92361111, 0.93333333, 0.94305556, 0.95277778, 0.9625    ,\n",
       "        0.97222222]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(scores, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do this more simply using the `mne.decoding` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatio-temporal: 81.7%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from mne.decoding import Scaler, Vectorizer, cross_val_multiscore\n",
    "\n",
    "epochs_decoding = epochs.copy().pick_types(meg='grad')\n",
    "\n",
    "clf = make_pipeline(Scaler(epochs_decoding.info),\n",
    "                    Vectorizer(),\n",
    "                    logreg)\n",
    "\n",
    "X = epochs_decoding.get_data()\n",
    "\n",
    "scores = cross_val_multiscore(clf, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "score = np.mean(scores, axis=0)\n",
    "print('Spatio-temporal: %0.1f%%' % (100 * score,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[............................................................] 100.00% Fitting SlidingEstimator |\n",
      "[............................................................] 100.00% Fitting SlidingEstimator |\n",
      "[............................................................] 100.00% Fitting SlidingEstimator |\n",
      "[............................................................] 100.00% Fitting SlidingEstimator |\n",
      "[............................................................] 100.00% Fitting SlidingEstimator |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sensor space decoding')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from mne.decoding import SlidingEstimator\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), logreg)\n",
    "\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc', verbose=True)\n",
    "scores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs.times, scores, label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "For more details see: https://mne.tools/stable/auto_tutorials/machine-learning/plot_sensors_decoding.html\n",
    "\n",
    "and this book chapter:\n",
    "\n",
    "Jean-RÃ©mi King, Laura Gwilliams, Chris Holdgraf, Jona Sassenhagen, Alexandre Barachant, Denis Engemann, Eric Larson, Alexandre Gramfort. Encoding and Decoding Neuronal Dynamics: Methodological Framework to Uncover the Algorithms of Cognition. 2018. https://hal.archives-ouvertes.fr/hal-01848442/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>Do a generalization over time analysis as explained in the <a href=\"https://mne.tools/stable/auto_tutorials/machine-learning/plot_sensors_decoding.html\">documentation on decoding</a>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
